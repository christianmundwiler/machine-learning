{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e5a003b4a7c4c98ed1bda383b5c07c2",
     "grade": false,
     "grade_id": "cell-633e5f428efb4489",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Programming Assignment 3\n",
    "## On clustering algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "26979a5c4c0e8a560f836cb20adb4e0c",
     "grade": false,
     "grade_id": "cell-4488e2332a605fe6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Dataset & Assumptions\n",
    "* `the-dataset.csv` -- The dataset represents three intertwined spirals, each with approximately 100 two-dimensional data points. Please see a plot of all the points below. The three spirals are intentionally given colors (blue, red and green) to emphasize the obvious 3-clusterings as you can see below. I believe you can appreciate how human eyes/head/brain can distinguish the three clusters quite easily!\n",
    "    * The file contains three columns, corresponding to the `X` and `Y` coordinates in the Cartesian plane, as well as the cluster number in the third column of the csv file are to denote only the membership of each data point to one of the three clusters. \n",
    "    * Please note that the cluster numbers are irrelevant in clustering as it is an unsupervised learning algorithm. \n",
    "    * However, as we happen to have received the true clustering results embedded in the dataset, we can leverage this extra information to evaluate the clustering results externally, with a metric affectionately known as the `RandIndex` (an extrinsic metric for evaluation).\n",
    "    * Just to let you know the intrinsic metric, `sum-of-squared-error` wouldn't use that extra information as it relies on how compact your clustering results are.\n",
    "* It should be noted that this type of dataset is difficult to cluster! But, I have trust in you; I believe you are clever enough to employ the appropriate clustering algorithm with tricks to properly cluster the dataset.\n",
    "* You need to explore most of the clustering approaches you learned in the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a00424c4acbb71401684e74a1f6016f",
     "grade": false,
     "grade_id": "cell-5fc1ef5d5a244df0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Restrictions to solve this assignment\n",
    "* NO LIBRARY FUNCTIONS to do `k-means` and/or `hierarchical clustering` WILL BE ALLOWED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d334d804982dd46c446fbde959e0978b",
     "grade": false,
     "grade_id": "cell-01bacac9d25d6419",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "992c2e08c3f470a735c92c73c7df6ed0",
     "grade": false,
     "grade_id": "cell-92eb79f09da3f090",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### The imports\n",
    "* You are allowed to import additional packages wherever you think necessary. Please write the import statements there, but not here.\n",
    "* Make sure you don't import/use any package/function that solves either of the k-means, hierarchical clustering, or directly solving a specific task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "342709fd22f5b1ee858410ec3ba00cd8",
     "grade": false,
     "grade_id": "cell-eac0096725ab9a89",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from scipy.special import comb\n",
    "from scipy import mean\n",
    "from itertools import combinations\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import pearsonr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c9d68758946d22ec8ef8094e4fd0be5",
     "grade": false,
     "grade_id": "cell-0cf192b46eb3c515",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Loading the-dataset into the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe502af8aad41635e04997dd35361954",
     "grade": false,
     "grade_id": "cell-bd4355f25b0c5588",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('the-dataset.csv', delim_whitespace=True, header=None)\n",
    "data = np.array(data_df.iloc[:,:-1]) #the dataset\n",
    "true_membership = np.array(data_df.iloc[:,-1]) #cluster membership of each of the data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f8bcb375d3cfec4bb2c7066dbb59c11",
     "grade": false,
     "grade_id": "cell-171657e4b01ea8c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### ScatterPlot utility function\n",
    "* third column need to represent the color value of points to plot not the z co-ordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33df801f0acd3a844cd67a55a07d657d",
     "grade": false,
     "grade_id": "cell-0ea6775c639e77ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def scatterPlot (data,membership,centroids=None,plotTitle = \"The Dataset\"):\n",
    "    \"\"\"\n",
    "    This function draw a scatter plot of data points with cluster membership given.\n",
    "    \n",
    "    :param data: a numpy array of data points. \n",
    "    :param membership: a list of cluster membership of each of the data points in `data'.\n",
    "                       a membership value can be any natural number beginning with 1, 2, ...\n",
    "    :param centroids: a numpy array of centroids (optional)\n",
    "    \n",
    "    param plotTitle: The title of the plot. Defaults to \"The Dataset\"\n",
    "    \n",
    "    return nothing. But it draws a scatter plot of the data points and centroids are marked with asterisks.\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    membership = np.array(membership)\n",
    "    \n",
    "    n,m = data.shape\n",
    "    assert m==2 #maximum 2-dim samples due to the fact that it's a scatter plot\n",
    "    k = len(centroids)\n",
    "    assert(k<=7) #Maximum 7 clusters due to limitation of available colors\n",
    "    plt.figure(num=None, figsize=(6, 6), dpi=80)\n",
    "    colorArray = []\n",
    "    available_colors = [\"\",\"b\",\"g\",\"r\",\"c\",\"m\",\"y\",\"k\"]\n",
    "    for i in membership:\n",
    "        colorArray.append(available_colors[i])\n",
    "        \n",
    "    plt.scatter(data[:,0],data[:,1],facecolor=\"none\", edgecolors=colorArray, s=30)\n",
    "    if centroids is not None:\n",
    "        for i in range(len(centroids)):\n",
    "            plt.scatter(centroids[i,0],centroids[i,1],\n",
    "                        facecolor=\"none\",edgecolors=available_colors[i+1],marker=\"*\",s=150)\n",
    "    plt.title(plotTitle)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "86d3eeea595d43bd08ebcd48392c3890",
     "grade": false,
     "grade_id": "cell-a1e5699478f9e0a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task A\n",
    "* Generate a figure from the given dataset belonging to 3 clusters in the Cartesian scatter plot that resembles the following. Please don't copy the figure.\n",
    "    - It resonates the 3 clusters.\n",
    "![clustering-scatterplot](figs/cluster_results_x-2.png)\n",
    "* You may use the utility function `scatterPlot()` defined above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08946113da4b34997b5b0b2f928ab7c0",
     "grade": false,
     "grade_id": "cell-d03950f54ffc0faf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def getCentroids(data,membership):\n",
    "    \"\"\" this function computes the centroids for the given dataset\n",
    "    \n",
    "    :param data: a numpy array of data points. \n",
    "    :param membership: a list of cluster membership of each of the data points in `data'.\n",
    "                       a membership value can be any natural number beginning with 1, 2, ...\n",
    "    :return centroids: a numpy array of centroids\n",
    "    \"\"\"\n",
    "    \n",
    "    #n = number of samples in the dataset data\n",
    "    #m = dimension of each of the n samples\n",
    "    data = np.array(data)\n",
    "    membership = np.array(membership)\n",
    "    n,m = data.shape\n",
    "    \n",
    "    centroid_ids = np.unique(membership)\n",
    "    k = len(centroid_ids) #number of clusters\n",
    "    centroids = np.zeros((k,m))\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1213367d6bb8fb295b36663ca6b65f94",
     "grade": true,
     "grade_id": "cell-6742893166f151e4",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#First compute centroids based on true memberships given in the dataset. Use getCentroid function\n",
    "#Then, plot the scatterplot of the datapoints with true_membership. Use scatterPlot function\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36a50ca7e7523041b0845b6259c65319",
     "grade": true,
     "grade_id": "cell-0791093f3768915a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Basic check to your solution for this task\n",
    "assert np.abs(np.sqrt(np.sum( \\\n",
    "    (getCentroids(data,true_membership)[0]-getCentroids(data,true_membership)[1])*\\\n",
    "    (getCentroids(data,true_membership)[0]-getCentroids(data,true_membership)[1]))) + \\\n",
    "              np.sqrt(np.sum( \\\n",
    "    (getCentroids(data,true_membership)[0]-getCentroids(data,true_membership)[2])*\\\n",
    "    (getCentroids(data,true_membership)[0]-getCentroids(data,true_membership)[2]))) + \\\n",
    "              np.sqrt(np.sum( \\\n",
    "    (getCentroids(data,true_membership)[1]-getCentroids(data,true_membership)[2])*\\\n",
    "    (getCentroids(data,true_membership)[1]-getCentroids(data,true_membership)[2])))-9.889345077209153)<1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6b93a2cf63ee4e15c79c5db5d9c91b7",
     "grade": false,
     "grade_id": "cell-7ba50e269ba68b35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task B\n",
    "* Define the function: `EuclideanDistance()` based on the specification.\n",
    "* Details can be found on Slide 23 of lecture [Lecture-PDF](https://drive.google.com/file/d/1uu-LkqTQc-VNrlkhhSdzeKyfThnhLecn/view), [Lecture-Video](https://www.youtube.com/embed/vzlCnJT2sbY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54bef6fe89d6a84b7ec6c41d319b12fd",
     "grade": false,
     "grade_id": "cell-f5faba6d927914d2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def EuclideanDistance(x1,x2):\n",
    "    \"\"\"\n",
    "    Calculates Euclidean distance between two data points.\n",
    "    \n",
    "    :param x1: a numpy array (or a list) representing a multi-dimensional data point.\n",
    "    :param x2: a numpy array (or a list) representing a multi-dimensional data point.\n",
    "    :return : Euclidean distance between the data points x1 and x2.\n",
    "    \"\"\"\n",
    "    distance_val = 0\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return distance_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26bf0abce4e4098f5e7c7f1a9fb8a752",
     "grade": true,
     "grade_id": "cell-8c0c5ec3b1d74274",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Testing your solution. Please note there are hidden test cases.\n",
    "assert(np.abs(EuclideanDistance([10, 20],[12, 24])-4.47213595499958)<=1e-4)\n",
    "assert(np.abs(EuclideanDistance([12, 24],[10, 20])-4.47213595499958)<=1e-4)\n",
    "assert(np.abs(EuclideanDistance([12, 24],[12, 24])-0.0)<=1e-4)\n",
    "assert(np.abs(EuclideanDistance([-12, 24],[12, -24])-53.665631459994955)<=1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3605fac360dd44194d184316406a5b03",
     "grade": false,
     "grade_id": "cell-fe4587010682e579",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task C\n",
    "* Define the function: `CosineSimilarity()` based on the specification.\n",
    "* Details can be found on Slide 32 of lecture [Lecture-PDF](https://drive.google.com/file/d/1uu-LkqTQc-VNrlkhhSdzeKyfThnhLecn/view), [Lecture-Video](https://www.youtube.com/embed/vzlCnJT2sbY)\n",
    "* Please note: The cosine similarity always belongs to the interval [-1,1]. For example, two proportional vectors have a cosine similarity of 1, two orthogonal vectors have a similarity of 0, and two opposite vectors have a similarity of -1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45c33d7a2b4d9befb24794b46f29160a",
     "grade": false,
     "grade_id": "cell-0848f6183378eaed",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def CosineSimilarity(x1,x2):\n",
    "    \"\"\"\n",
    "    Calculates cosine similarity between two data points.\n",
    "    \n",
    "    :param x1: a numpy array (or a list) representing a multi-dimensional data point.\n",
    "    :param x2: a numpy array (or a list) representing a multi-dimensional data point.\n",
    "    :return : cosine similarity between the data points x1 and x2.\n",
    "    \"\"\"\n",
    "    similarity_val = 0\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return similarity_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9381afc43c6cb32f0ebc3e9cd2c12b5",
     "grade": true,
     "grade_id": "cell-f4f8aa01c8539860",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Testing your solution. Please note there are few hidden tests.\n",
    "assert(np.abs(CosineSimilarity([10, 20],[12, 24])-0.9999999999999998)<=1e-4)\n",
    "assert(np.abs(CosineSimilarity([12, 24],[10, 20])-0.9999999999999998)<=1e-4)\n",
    "assert(np.abs(CosineSimilarity([12, 24],[12, 24])-1.0)<=1e-4)\n",
    "assert(np.abs(CosineSimilarity([-12, 24],[12, -24])-(-1.0))<=1e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5247170db917d82a7a79918291051a4c",
     "grade": false,
     "grade_id": "cell-811bdba929de1384",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task D\n",
    "* Define the function: `cosineDistance()` based on the specification.\n",
    "    - Cosine distance is commonly used for the complement of cosine similarity in positive space with the following formula:\n",
    "    $$\n",
    "        cosineDistance(x1,x2) = 1 - cosineSimilarity(x1,x2)\n",
    "    $$\n",
    "* Please note: Since range of cosine similarity is [-1,1], the range of cosine distance is thus [0,2]\n",
    "* Also note: the cosine distance is not a proper distance metric as it does not have the triangle inequality property. More on this [https://en.wikipedia.org/wiki/Cosine_similarity](https://en.wikipedia.org/wiki/Cosine_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7440985a5c9d519c00a45f5815af37a",
     "grade": false,
     "grade_id": "cell-dcba09e9ecd11bde",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def CosineDistance(x1,x2):\n",
    "    \"\"\"\n",
    "    Calculates cosine distance between two data points.\n",
    "    \n",
    "    :param x1: a numpy array (or a list) representing a multi-dimensional data point.\n",
    "    :param x2: a numpy array (or a list) representing a multi-dimensional data point.\n",
    "    :return : cosine distance between the data points x1 and x2.\n",
    "    \"\"\"\n",
    "    distance = 0\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d2437230b5e8292b87fd08585677f32",
     "grade": true,
     "grade_id": "cell-c95066e24245a01a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Testing your solution. Please note there are few hidden tests.\n",
    "assert(np.abs(CosineDistance([10, 20],[12, 24])-0.0)<=1e-4)\n",
    "assert(np.abs(CosineDistance([12, 24],[10, 20])-0.0)<=1e-4)\n",
    "assert(np.abs(CosineDistance([12, 24],[12, 24])-0.0)<=1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2fcb6fcf7f728325dbc33ab4323f44e5",
     "grade": false,
     "grade_id": "cell-2f82997a9d79a7df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task E\n",
    "* Define the function: `MinkowskiDistance()` based on the specification.\n",
    "* Details can be found on Slide 25 of lecture [Lecture-PDF](https://drive.google.com/file/d/1uu-LkqTQc-VNrlkhhSdzeKyfThnhLecn/view), [Lecture-Video](https://www.youtube.com/embed/vzlCnJT2sbY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f3102b359ef2aae4e942dd28acc005b",
     "grade": false,
     "grade_id": "cell-a0fc93628e0750a1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def MinkowskiDistance(x1,x2,p=3):\n",
    "    \"\"\"\n",
    "    Calculates Minkowski distance (of order `p`) between two data points.\n",
    "    \n",
    "    :param x1: a numpy array (or a list) representing a multi-dimensional data point.\n",
    "    :param x2: a numpy array (or a list) representing a multi-dimensional data point.\n",
    "    :param p: the order of Minkowski distance. defaults to 3.\n",
    "    :return : Minkowski distance between the data points x1 and x2.\n",
    "    \"\"\"\n",
    "    distance_val = 0\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return distance_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3f4a7f2ad6e6aa9391d1dc54a240d8a",
     "grade": true,
     "grade_id": "cell-89d57405646e3f6a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Let's test your implementation above\n",
    "assert(np.abs(MinkowskiDistance(x1=[10, 20, 15, 10, 5],x2=[12, 24, 18, 8, 7],p=1)-13.0)<1e-4)\n",
    "assert(np.abs(MinkowskiDistance(x1=[10, 20, 15, 10, 5],x2=[12, 24, 18, 8, 7],p=2)-6.082762530298219)<1e-4)\n",
    "assert(np.abs(MinkowskiDistance(x1=[10, 20, 15, 10, 5],x2=[12, 24, 18, 8, 7],p=3)-4.862944131094279)<1e-4)\n",
    "assert(np.abs(MinkowskiDistance([10, 20],[12, 24],p=1)-6.0)<=1e-4)\n",
    "assert(np.abs(MinkowskiDistance([10, 20],[12, 24],p=2)-4.47213595499958)<=1e-4)\n",
    "assert(np.abs(MinkowskiDistance([10, 20],[12, 24],p=3)-4.160167646103808)<=1e-4)\n",
    "assert(np.abs(MinkowskiDistance([12, 24],[10, 20],p=1)-6.0)<=1e-4)\n",
    "assert(np.abs(MinkowskiDistance([12, 24],[10, 20],p=2)-4.47213595499958)<=1e-4)\n",
    "assert(np.abs(MinkowskiDistance([12, 24],[10, 20],p=3)-4.160167646103808)<=1e-4)\n",
    "assert(np.abs(MinkowskiDistance([12, 24],[12, 24],p=1)-0.0)<=1e-4)\n",
    "assert(np.abs(MinkowskiDistance([12, 24],[12, 24],p=2)-0.0)<=1e-4)\n",
    "assert(np.abs(MinkowskiDistance([12, 24],[12, 24],p=3)-0.0)<=1e-4)\n",
    "assert(np.abs(MinkowskiDistance([-12, 24],[12, -24],p=1)-72.0)<=1e-4)\n",
    "assert(np.abs(MinkowskiDistance([-12, 24],[12, -24],p=2)-53.665631459994955)<=1e-4)\n",
    "assert(np.abs(MinkowskiDistance([-12, 24],[12, -24],p=3)-49.92201175324569)<=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9f3dba030b5153c8a323b823580b919",
     "grade": false,
     "grade_id": "cell-46e4451c244396e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task F\n",
    "* Define function SSE of clustering results.\n",
    "* Details can be found on Slide # 52 of lecture [Lecture-PDF](https://drive.google.com/file/d/1fT_kCI-i8eyXdvI10nP_mNUtS4bE5mU8/view), [Lecture-Video](https://www.youtube.com/embed/WZpmaQ5eUus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7121f200f1ffeca98cdaf5bc164c326",
     "grade": false,
     "grade_id": "cell-15831fd9705ec91e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def SSE(data,membership):\n",
    "    \"\"\"\n",
    "    Calculates the sum of squared error of a clustering result involving the given data points.\n",
    "    \n",
    "    :param data: a numpy array of data points. \n",
    "    :param membership: a list of cluster membership of each of the data points in `data'.\n",
    "                       a membership value can be any natural number beginning with 1, 2, ...\n",
    "    :return sse_val: value of the sum of squared error based on the definition\n",
    "    \"\"\"\n",
    "    sse_val = 0\n",
    "    data = np.array(data)\n",
    "    membership = np.array(membership)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return sse_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "501e5eb1609bd6a663f4aefa3d6d00bd",
     "grade": true,
     "grade_id": "cell-308f75c8f3c82ee3",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Now, let's test your SSE function\n",
    "assert np.abs(SSE([[1,1],[2,2],[3,3],[4,4],[5,5]],[1,1,1,2,2])-5)<1e-4\n",
    "assert np.abs(SSE([[1,0],[3,0],[8,0],[10,0]],[1,1,2,2])-4)<1e-4\n",
    "assert np.abs(SSE([[1,0],[3,0],[8,0],[10,0]],[1,1,1,2])-26.0)<1e-4\n",
    "assert np.abs(SSE([[8,9],[0,8],[8,2]],[1,1,1])-71.33333333333333)<1e-4\n",
    "assert np.abs(SSE([[8,9],[0,8],[8,2]],[1,1,2])-32.49999999999999)<1e-4\n",
    "assert np.abs(SSE([[8,9],[0,8],[8,2]],[1,2,1])-24.5)<1e-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a803f09f67f3161530ed4a4f158d907b",
     "grade": false,
     "grade_id": "cell-bbfb9ebafe9d6c2c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task G\n",
    "* Complete the `RandIndex()` function in the cell below.\n",
    "* Rand Index (RI) is an external evaluation metric that requires ground true clustering result, unlike the `SSE` metric you defined above.\n",
    "* Here is the definition of `Rand Index (RI)`:\n",
    "    - This metric utilizes the ground-true labels of each of the data samples, that is quite unlike for unsupervised learning paradigm. But, here you were given a dataset with truth values associated to each sample, you could take advantage of that, right? RI metric is only applicable to this type of situation. Got it?\n",
    "    - It is based on a series of decisions, one for each of the $\\dfrac{n(n-1)}{2}$ pairs of the $n$ data samples in the dataset. We want to assign two data samples $(a, b)$ to the same cluster if and only if they are similar.\n",
    "        * **True positive (TP)** decision assigns two similar samples to the same cluster. That is, if the data samples $a$ and $b$ belong to the same cluster according to the ground truth, as well as in predicted clustering, it counts as a TP assignment.\n",
    "        * **True negative (TN)** decision assigns two dissimilar samples in to two different clusters. That is, if the data samples $a$ and $b$ belong to two different clusters in the ground truth, as well as in predicted clustering, it counts as a TN assignment.\n",
    "        * The above two cases (i.e., TP and TN) are correctly clustering instances. However, there are two types of errors we can commit:\n",
    "            - **False Positive (FP)** assigns two dissimilar samples to the same cluster. That is, if the samples $a$, and $b$ belong to different clusters in the ground truth, but your predicted clustering puts them into the same cluster, you accrue one FP assignment.\n",
    "            - **False Negative (FN)** assigns two similar samples into two different clusters. That is, if the samples $a$, and $b$ belong to the same cluster in the ground truth, but your predicted clustering puts them into two different clusters, you accrue one FN assignment.\n",
    "* This external evaluation metric, `Rand Index, RI` measures the percentage of clustering decisions that are correct. In simple term, it sounds a lot like accuracy, and we can treat it as the clustering accuracy:\n",
    "$$\n",
    "RI=\\dfrac{TP+TN}{TP+TN+FP+FN}\n",
    "$$\n",
    "* You can observe that cluster indices for each sample in a clustering result do not matter in computing the RI. You can literally use anything to mark the cluster memberships for each of the data samples, and you should get the same Rand Index value.\n",
    "* For a complete workout example, please look at this webpage [https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-clustering-1.html](https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-clustering-1.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c745860dadc27ec8f9bf34c3b2f502ad",
     "grade": false,
     "grade_id": "cell-82e03575cd11b358",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def RandIndex(data, true_membership, predicted_membership):\n",
    "    \"\"\"\n",
    "    Calculates the Rand Index (RI) of a clustering result involving the given data points \n",
    "    and their true memberships.\n",
    "    \n",
    "    :param data: a numpy array of data points. \n",
    "    :param true_membership: a list of ground true cluster membership of each of the data points in `data`.\n",
    "                       a membership value can be any natural number beginning with 1, 2, ...\n",
    "    :param predicted_membership: a list of predicted cluster membership of each of the data points in `data`.\n",
    "                       a membership value can be any natural number beginning with 1, 2, ...\n",
    "    :return ri_val: value of the rand index of the clustering result.\n",
    "    \"\"\"\n",
    "    ri_val = 0\n",
    "    data = np.array(data)\n",
    "    true_membership = np.array(true_membership)\n",
    "    predicted_membership = np.array(predicted_membership)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return ri_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "563f5d69ff421a08f4aecf6000dda244",
     "grade": true,
     "grade_id": "cell-b2007740afee001c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Now, let's test your rand index implementation\n",
    "assert np.abs(RandIndex([[1,1],[2,2],[3,3],[4,4],[5,5]],[1,1,1,2,2],[1,1,1,2,2])-1.0)<1e-4\n",
    "assert np.abs(RandIndex([[1,0],[3,0],[8,0],[10,0]],[1,1,2,2],[1,1,2,2])-1.0)<1e-4\n",
    "assert np.abs(RandIndex([[1,0],[3,0],[8,0],[10,0]],[1,1,1,2],[1,1,1,2])-1.0)<1e-4\n",
    "assert np.abs(RandIndex([[8,9],[0,8],[8,2]],[1,1,1],[1,1,1])-1.0)<1e-4\n",
    "assert np.abs(RandIndex([[8,9],[0,8],[8,2]],[1,1,2],[1,1,2])-1.0)<1e-4\n",
    "\n",
    "assert np.abs(RandIndex([[1,1],[2,2],[3,3],[4,4],[5,5]],[1,1,1,2,2],[3,3,3,5,5])-1.0)<1e-4\n",
    "assert np.abs(RandIndex([[1,1],[2,2],[3,3],[4,4],[5,5]],[1,1,1,2,2],[1,2,1,3,3])-0.8)<1e-4\n",
    "assert np.abs(RandIndex([[1,1],[2,2],[3,3],[4,4],[5,5]],[1,1,1,2,2],[1,1,1,1,2])-0.6)<1e-4\n",
    "assert np.abs(RandIndex([[1,1],[2,2],[3,3],[4,4],[5,5]],[1,1,1,2,2],[1,2,2,2,2])-0.4)<1e-4\n",
    "assert np.abs(RandIndex([[1],[2],[3],[4],[5],[6],[7],[8],[9],[10],[11],[12],[13],[14],[15],[16],[17]],\n",
    "            [1,1,1,1,1,1,2,2,2,2,2,2,3,3,3,3,3],\n",
    "            [3,2,3,3,3,3,3,2,2,2,1,2,3,1,3,1,1])-0.6764705882352942)<1e-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2f6eba72a89cb15949f720cd9d6f2d7",
     "grade": false,
     "grade_id": "cell-276aa52fbde1dfd1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task H\n",
    "* Implement the k-means clustering algorithm. Please do not use/call any library function that directly solves k-means clustering.\n",
    "* For distance calculation between pairs of data points use your own `EuclideanDistance()` function that you defined above.\n",
    "* For centroid calculation, use `getCentroids()` function you defined above.\n",
    "* Details can be found on Slide # 34 of lecture [Lecture-PDF](https://drive.google.com/file/d/1fT_kCI-i8eyXdvI10nP_mNUtS4bE5mU8/view?usp=sharing), [Lecture-Video](https://www.youtube.com/embed/WZpmaQ5eUus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0bf180873d00c9df26e46a2b24e35429",
     "grade": false,
     "grade_id": "cell-9536adf62286af85",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def MyKMeans(data, K, max_iter = 300, tol=1e-4, verbose=False, seed=54321):\n",
    "    \"\"\"\n",
    "    K-Means clustering.\n",
    "    \n",
    "    :param data: a numpy array of data points. \n",
    "    :param K: The number of clusters to form as well as the number of centroids to generate.\n",
    "    :param max_iter: Maximum number of iterations of the k-means algorithm for a single run.\n",
    "                     Defaults to 100.\n",
    "    :param tol:Relative tolerance with regards to Frobenius norm of the difference in \n",
    "                the cluster centers of two consecutive iterations to declare convergence.\n",
    "                Defaults to 1e-4\n",
    "    :param verbose: a Boolean flag helps in debugging. Defaults to False\n",
    "    :param seed: Seed value for random number generator. It helps to reproduce the results.\n",
    "    :return centroids which is a numpy array of shape (K,m), where m is the dimension of each point.\n",
    "    :return membership: a list of cluster membership of each of the data points in `data'.\n",
    "                       a membership value can be any natural number beginning with 1, 2, ...\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    data = np.array(data)\n",
    "    n,m = data.shape #n = num of samples, m = dim of each sample\n",
    "    \n",
    "    membership = np.zeros((n,),dtype=int)\n",
    "    \n",
    "    #step 1: select K points in the dataset as the initial K centroids\n",
    "    \n",
    "    centroids = random.sample(list(data), K)\n",
    "    \n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return centroids, membership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5ecab0a2e3092a2dde1905c165dfb15f",
     "grade": false,
     "grade_id": "cell-7eda12ab067c7319",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task I\n",
    "* Define the following `task_I()` function that does the following:\n",
    "    1. Run `MyKMeans()` to perform k-means clustering with `K=3`. Please keep other parameters to their default values.\n",
    "    2. Run `ScatterPlot()` to draw the result of clustering you got, with title `MyKMeans with k=3, SSE=x, RI=y` and replace `x, y` with the SSE and RI value of the clustering upto 2 digits after decimal point.\n",
    "* A sample \"expected\" output is shown below. Please don't copy the image below. LOL\n",
    "\n",
    "![task-i-kmeans](figs/kmean-task-I.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec45a4fe830a23e8c71d041f87cf7a2e",
     "grade": false,
     "grade_id": "cell-db3a5963766fe6cf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def task_I():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c300f28711c8e49cca3616319bb38ba",
     "grade": true,
     "grade_id": "cell-888cb79547f731b1",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#now call your task_I function below.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e06e7aefc649d818a913645891eaf2e1",
     "grade": false,
     "grade_id": "cell-2313164ef6fbd15c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task J\n",
    "*   Complete the following definition of `MyKMeans_version2()` with extra parameter `n_init` to run your very own `MyKMeans()` that many times and returns the best clustering among all these runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4680db63bdd89e119d4f0de411c1b194",
     "grade": false,
     "grade_id": "cell-f40b2ae3109ee08a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def MyKMeans_version2(data, K, max_iter = 300, tol=1e-4, n_init=10, verbose=False, seed=54321, seed_list=None):\n",
    "    \"\"\"\n",
    "    K-Means clustering that runs k-means several times and returns best clustering results of all runs.\n",
    "    \n",
    "    :param data: a numpy array of data points. \n",
    "    :param K: The number of clusters to form as well as the number of centroids to generate.\n",
    "    :param max_iter: Maximum number of iterations of the k-means algorithm for a single run.\n",
    "                     Defaults to 100.\n",
    "    :param tol:Relative tolerance with regards to Frobenius norm of the difference in \n",
    "                the cluster centers of two consecutive iterations to declare convergence.\n",
    "                Defaults to 1e-4\n",
    "    :param n_init: Number of times the MyKMeans algorithm will be run with different centroid seeds. \n",
    "                    The final results will be the best output of n_init runs based on SSE scores.\n",
    "                    Defaults to 10.\n",
    "    :param verbose: a Boolean flag helps in debugging. Defaults to False\n",
    "    :param seed: Seed value for random number generator. It helps to reproduce the results.\n",
    "    :param seed_list: List of seed values for each run of MyKMeans to the random number generator. \n",
    "                    It helps to reproduce results. len(seed_list)==n_init or seed_list is None in that case\n",
    "                    n_init number of seeds will be generated.\n",
    "    :return best_centroids which is a numpy array of shape (K,m), where m is the dimension of each point.\n",
    "    :return best_membership: a list of cluster membership of each of the data points in `data'.\n",
    "                       a membership value can be any natural number beginning with 1, 2, ...\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    if seed_list is None:\n",
    "        seed_list = [random.randint(10000, 60000) for i in range(n_init)]\n",
    "    assert len(seed_list)==n_init\n",
    "    \n",
    "    best_centroids = []\n",
    "    best_membership = []\n",
    "    best_sse_val = np.inf\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return best_centroids,best_membership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d477c3dfc404efb175dd7e36fd7d936",
     "grade": false,
     "grade_id": "cell-24d7bdd65be24616",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task K\n",
    "* Define the following `task_K()` function that does the following:\n",
    "    1. Run `MyKMeans_version2()` to perform k-means clustering with `K=3`, and `n_init=10`. Please keep other parameters to their default values.\n",
    "    2. Run `ScatterPlot()` to draw the result of clustering you got, with title `MyKMeans_version2 with k=3, SSE=x, RI=y` and replace `x, y` with the SSE and RI value of the clustering upto 2 digits after decimal point.\n",
    "* A sample \"expected\" output is shown below. Please don't copy the image below. LOL\n",
    "\n",
    "![task-k-kmeans](figs/kmean-task-k.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ad6bd59dc1da1e2a1c1e7a53bf5ca2f",
     "grade": false,
     "grade_id": "cell-402187eaecd67d4c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def task_K():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6cb5ebf976147d8b353275268d89f1ab",
     "grade": true,
     "grade_id": "cell-815bda5ff093f779",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Now calling your task_K() to see how it looks.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad562f5d0fb68f8f4720479c00c74bc4",
     "grade": false,
     "grade_id": "cell-8bccc59816eb6fd2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task L\n",
    "* Alright, so far so good?\n",
    "* Now, we will be shifting gears towards `Hierarchical Clustering`. Ready?\n",
    "* First task would be to completely define the following `linkageDistance()` function that computes distance between two clusters based on the linkage_type and distance metric adopted.\n",
    "* Details can be found on Slide # 72+ of lecture [Lecture-PDF](https://drive.google.com/file/d/1Tfl4tgX72a-Oy1GN_3SoV9vYgT9MnaWr/view?usp=sharing), [Lecture-Video](https://www.youtube.com/embed/mrCnL9jnsOc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22cd408a550584f361cb81e10e1fd172",
     "grade": false,
     "grade_id": "cell-c7d255a7b42c3cad",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def linkageDistance(cluster1,cluster2,linkage_type,distance_metric):\n",
    "    \"\"\"\n",
    "    Computes distance between two clusters based on the linkage_type and distance metric adopted.\n",
    "    \n",
    "    :param cluster1: a numpy array of data points\n",
    "    :param cluster2: a numpy array of data points\n",
    "    :param linkage_type: a string from the set of linkage type strings: \n",
    "                        {\"single\", \"complete\", \"average\"}\n",
    "    :param distance_metric: a string from the set of distance metric strings: \n",
    "                        {\"Euclidean\", \"CosineDistance\", \"Minkowski_3\"}\n",
    "        referring to Euclidean distance, Cosine distance and Minkowski distance with order,p=3\n",
    "    :return distance : it returns the linkage distance between the two clusters.\n",
    "    \"\"\"\n",
    "    distance = -1\n",
    "    assert linkage_type in [\"single\", \"complete\", \"average\"]\n",
    "    assert distance_metric in [\"Euclidean\", \"CosineDistance\", \"Minkowski_3\"]\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return distance         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf130fb8c5f395ab103d290031793672",
     "grade": true,
     "grade_id": "cell-7dd0d1c8b8637aee",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Few test cases for evaluating your implementation of linkageDistance()\n",
    "assert np.abs(\\\n",
    "    linkageDistance(cluster1=[[1,1]],\n",
    "                    cluster2=[[1.5,1.5]],\n",
    "                    linkage_type='single',\n",
    "                    distance_metric='Euclidean')-0.7071067811865476) < 1e-4\n",
    "assert np.abs(\\\n",
    "    linkageDistance(cluster1=[[3,4],[3,3.5]],\n",
    "                    cluster2=[[5,5]],\n",
    "                    linkage_type='single',\n",
    "                    distance_metric='Euclidean')-2.23606797749979) < 1e-4\n",
    "\n",
    "assert np.abs(\\\n",
    "    linkageDistance(cluster1=[[3,4],[3,3.5]],\n",
    "                    cluster2=[[1,1],[1.5,1.5]],\n",
    "                    linkage_type='single',\n",
    "                    distance_metric='Euclidean')-2.5) < 1e-4\n",
    "\n",
    "assert np.abs(\\\n",
    "    linkageDistance(cluster1=[[3,4],[3,3.5],[4,4]],\n",
    "                    cluster2=[[1,1],[1.5,1.5]],\n",
    "                    linkage_type='single',\n",
    "                    distance_metric='Euclidean')-2.5) < 1e-4\n",
    "\n",
    "assert np.abs(\\\n",
    "    linkageDistance(cluster1=[[3,4],[3,3.5],[4,4],[5,5]],\n",
    "                    cluster2=[[1,1],[1.5,1.5]],\n",
    "                    linkage_type='single',\n",
    "                    distance_metric='Euclidean')-2.5) < 1e-4\n",
    "\n",
    "assert np.abs(\\\n",
    "    linkageDistance(cluster1=[[3,4],[3,3.5]],\n",
    "                    cluster2=[[1,1],[1.5,1.5]],\n",
    "                    linkage_type='complete',\n",
    "                    distance_metric='Euclidean')-3.605551275463989) < 1e-4\n",
    "\n",
    "assert np.abs(\\\n",
    "    linkageDistance(cluster1=[[3,4],[3,3.5],[4,4]],\n",
    "                    cluster2=[[1,1],[1.5,1.5]],\n",
    "                    linkage_type='average',\n",
    "                    distance_metric='Euclidean')-3.333460655775848) < 1e-4\n",
    "\n",
    "assert np.abs(\\\n",
    "    linkageDistance(cluster1=[[3,4],[3,3.5],[4,4],[5,5]],\n",
    "                    cluster2=[[1,1],[1.5,1.5]],\n",
    "                    linkage_type='single',\n",
    "                    distance_metric='Minkowski_3')-2.2489707226377074) < 1e-4\n",
    "\n",
    "assert np.abs(\\\n",
    "    linkageDistance(cluster1=[[3,4],[3,3.5],[4,4],[5,5]],\n",
    "                    cluster2=[[1,1],[1.5,1.5]],\n",
    "                    linkage_type='single',\n",
    "                    distance_metric='CosineDistance')-0.0) < 1e-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cca9e003b82fcfc0342c6ab0966006e2",
     "grade": false,
     "grade_id": "cell-d9df963fee5c181a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task M\n",
    "* Completely define the following `computeDistanceMatrix()` function that computes distance matrix of clusters based on the linkage_type and distance metric adopted.\n",
    "    - Please use your own `linkageDistance()` function above.\n",
    "* Details can be found on Slide # 72+ of lecture [Lecture-PDF](https://drive.google.com/file/d/1Tfl4tgX72a-Oy1GN_3SoV9vYgT9MnaWr/view?usp=sharing), [Lecture-Video](https://www.youtube.com/embed/mrCnL9jnsOc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ce132a516e517d4c0cbf077040a9984",
     "grade": false,
     "grade_id": "cell-c96346767a26529e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def computeDistanceMatrix(cluster_info, linkage_type,distance_metric, verbose=False):\n",
    "    \"\"\"Computes the distance matrix \n",
    "    \n",
    "    :param cluster_info: a dictionary with 2 keys: {'clusters', and 'members'}, where\n",
    "                    cluster_info['clusters'] is list of cluster of data points which are numpy arrays. \n",
    "                    For instance: cluster_info['clusters'] = \n",
    "                                    [ [\n",
    "                                        [1,1],\n",
    "                                        [2,2]\n",
    "                                    ], \n",
    "                                    [\n",
    "                                        [3,3],\n",
    "                                        [4,4],\n",
    "                                        [5,5],\n",
    "                                    ],\n",
    "                                    [\n",
    "                                        [6,6]\n",
    "                                    ] ] \n",
    "                    it denotes a list of 3 clusters having 2, 3 and 1 data points where each point is 2D.\n",
    "                    On the other hand, cluster_info['members'] is a list of cluster of indices of the data\n",
    "                    points.\n",
    "                    For instance: cluster_info['members'] = \n",
    "                                    [ \n",
    "                                        [0,1],\n",
    "                                        [2,3,4],\n",
    "                                        [5]\n",
    "                                    ]\n",
    "                    denotes the list of 3 clusters having 2,3,1 data points whose original indices are\n",
    "                    [0, 1, 2, 3, 4, 5].\n",
    "    :param linkage_type: a string from the set of linkage type strings: \n",
    "                        {\"single\", \"complete\", \"average\"}\n",
    "    :param distance_metric: a string from the set of distance metric strings: \n",
    "                        {\"Euclidean\", \"CosineDistance\", \"Minkowski_3\"}\n",
    "        referring to Euclidean distance, Cosine distance and Minkowski distance with order,p=3\n",
    "    :return distance_matrix: a numpy square matrix containing the distance matrix for the given clusters.\n",
    "    :return min_distance: minimum distance value in the computed distance matrix\n",
    "    :return min_clust1: index of the first cluster that yielded minimum distance\n",
    "    :return min_clust2: index of the second cluster that yielded minimum distance.\n",
    "        \n",
    "    \"\"\"\n",
    "    n_clusters = len(cluster_info['clusters']) #number of cluster\n",
    "    #if verbose: print('n_clusters = {}'.format(n_clusters))\n",
    "    distance_matrix = np.zeros((n_clusters,n_clusters))\n",
    "    min_distance = np.inf\n",
    "    min_clust1 = []\n",
    "    min_clust2 = []\n",
    "    min_i = -1\n",
    "    min_j = -1\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return distance_matrix, min_distance, min_i, min_j, min_clust1, min_clust2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ac8d41892ef3b6193731258acd3a548",
     "grade": true,
     "grade_id": "cell-d92784a38cc5ab61",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#test case to evaluate your implementation of computeDistanceMatrix()\n",
    "dMat,min_d,min_i,min_j,min_clust1,min_clust2 = \\\n",
    "    computeDistanceMatrix(cluster_info={\\\n",
    "                        'clusters':[ [[1,1]], [[1.5,1.5]], [[5,5]], [[3,4]], [[4,4]], [[3,3.5]] ],\\\n",
    "                        'members':[[0],[1],[2],[3],[4],[5]]},\\\n",
    "                          linkage_type='single',\n",
    "                          distance_metric='Euclidean'\n",
    "                         )\n",
    "assert np.abs(np.sqrt(np.sum(dMat**2))-16.80773631397161)<1e-4\n",
    "assert np.abs(min_d-0.5)<1e-4\n",
    "assert (min_i,min_j)==(3,5)\n",
    "assert (min_clust1,min_clust2)==([3],[5])\n",
    "\n",
    "\n",
    "dMat,min_d,min_i,min_j,min_clust1,min_clust2 = \\\n",
    "    computeDistanceMatrix(cluster_info={\\\n",
    "                        'clusters':[ [[1,1]], [[1.5,1.5]], [[5,5]], [[3,4],[3,3.5]], [[4,4]] ],\\\n",
    "                        'members':[[0],[1],[2],[3,5],[4]]},\\\n",
    "                          linkage_type='single',\n",
    "                          distance_metric='Euclidean'\n",
    "                         )\n",
    "assert np.abs(np.sqrt(np.sum(dMat**2))-14.966629547095767)<1e-4\n",
    "assert np.abs(min_d-0.7071067811865476)<1e-4\n",
    "assert (min_i,min_j)==(0, 1)\n",
    "assert (min_clust1,min_clust2)==([0], [1])\n",
    "\n",
    "dMat,min_d,min_i,min_j,min_clust1,min_clust2 = \\\n",
    "    computeDistanceMatrix(cluster_info={\\\n",
    "                        'clusters':[ [[1,1],[1.5,1.5]], [[5,5]], [[3,4],[3,3.5]], [[4,4]] ],\\\n",
    "                        'members':[[0,1],[2],[3,5],[4]]},\\\n",
    "                          linkage_type='single',\n",
    "                          distance_metric='Euclidean'\n",
    "                         )\n",
    "assert np.abs(np.sqrt(np.sum(dMat**2))-10.124228365658293)<1e-4\n",
    "assert np.abs(min_d-1.0)<1e-4\n",
    "assert (min_i,min_j)==(2,3)\n",
    "assert (min_clust1,min_clust2)==([3, 5], [4])\n",
    "\n",
    "dMat,min_d,min_i,min_j,min_clust1,min_clust2 = \\\n",
    "    computeDistanceMatrix(cluster_info={\\\n",
    "                        'clusters':[ [[1,1],[1.5,1.5]], [[5,5]], [[3,4],[3,3.5],[4,4]] ],\\\n",
    "                        'members':[[0,1],[2],[3,4,5]]},\\\n",
    "                          linkage_type='single',\n",
    "                          distance_metric='Euclidean'\n",
    "                         )\n",
    "assert np.abs(np.sqrt(np.sum(dMat**2))-8.093207028119323)<1e-4\n",
    "assert np.abs(min_d-1.4142135623730951)<1e-4\n",
    "assert (min_i,min_j)==(1, 2)\n",
    "assert (min_clust1,min_clust2)==([2], [3, 4, 5])\n",
    "\n",
    "\n",
    "dMat,min_d,min_i,min_j,min_clust1,min_clust2 = \\\n",
    "    computeDistanceMatrix(cluster_info={\\\n",
    "                        'clusters':[ [[1,1],[1.5,1.5]],[[3,4],[3,3.5],[4,4],[5,5]] ],\\\n",
    "                        'members':[[0,1],[2,3,4,5]]},\\\n",
    "                          linkage_type='single',\n",
    "                          distance_metric='Euclidean'\n",
    "                         )\n",
    "assert np.abs(np.sqrt(np.sum(dMat**2))-3.5355339059327378)<1e-4\n",
    "assert np.abs(min_d-2.5)<1e-4\n",
    "assert (min_i,min_j)==(0, 1)\n",
    "assert (min_clust1,min_clust2)==([0, 1], [2, 3, 4, 5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "878bbad510c30db7f730982b948db811",
     "grade": false,
     "grade_id": "cell-8085784699289fb8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task N\n",
    "* Complete the following `hierarchical_agglomerative_clustering()` function that follows the given input/output specifications.\n",
    "    - Please use `computeDistanceMatrix()` function that you defined above.\n",
    "* Details can be found on Slide # 72+ of lecture [Lecture-PDF](https://drive.google.com/file/d/1Tfl4tgX72a-Oy1GN_3SoV9vYgT9MnaWr/view?usp=sharing), [Lecture-Video](https://www.youtube.com/embed/mrCnL9jnsOc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8b1e8b707bbb94470b30af6f1fb9897",
     "grade": false,
     "grade_id": "cell-e90c01aa1fb2894a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def hierarchical_agglomerative_clustering(data, K, linkage_type, distance_metric, verbose=False):\n",
    "    \"\"\"\n",
    "    Perform hierarchical clustering using agglomerative strategy on the dataset based on the \n",
    "    given linkage type and distance metric.\n",
    "    \n",
    "    :param data: a numpy array of data points. \n",
    "    :param K: The number of clusters to form as well as the number of centroids to generate.\n",
    "    \n",
    "    :param linkage_type: a string from the set of linkage type strings: \n",
    "                        {\"single\", \"complete\", \"average\"}\n",
    "    :param distance_metric: a string from the set of distance metric strings: \n",
    "                        {\"Euclidean\", \"CosineDistance\", \"Minkowski_3\"}\n",
    "        referring to Euclidean distance, Cosine distance and Minkowski distance with order,p=3\n",
    "    :return K_membership: a list of K cluster membership of each of the data points in `data' by cutting\n",
    "                        the computed dendrogram at a certain height. Please note a membership value can \n",
    "                        be any natural number beginning with 1, 2, ...\n",
    "    :return first_distance_matrix: first computed distance matrix of the given data points.\n",
    "    :return cophenetic_matrix: cophenetic matrix of the given data points based on the merge events.\n",
    "    :return cluster_merge_log: returns a list of cluster merge events. Make sure each item of the list \n",
    "                        contains the following (in the following order):\n",
    "                        i) min_dist : the distance where two clusters were merged\n",
    "                        ii) min_clust1: the cluster1 in question who merged with ...\n",
    "                        iii) min_clust2: the cluster2.\n",
    "                        iv) clusters: a list of existing clustering of the original datapoints.\n",
    "                            For example: [[2], [0, 1], [3, 4, 5]]] for clusters denotes so far you've\n",
    "                            3 clusters and the first cluster having the data point 2 as the only member,\n",
    "                            second cluster having datapoints 0 and 1 as members,\n",
    "                            third cluster having data points 3, 4, and 5 as members.\n",
    "                        Please note: * you need to log before the merging event.\n",
    "                                     * first 3 items in the log list can be retrieved from each \n",
    "                                       computeDistanceMatrix() call.\n",
    "                        \n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    n,m = data.shape #n = number of points, m=dimension of a point\n",
    "    \n",
    "    K_membership = np.zeros((n,),dtype=int) #cluster membership array. Values can be anything 1,2,...K\n",
    "    \n",
    "    first_distance_matrix = np.zeros((n,n)) #first distance matrix involving n points.\n",
    "    \n",
    "    cophenetic_matrix = np.zeros_like(first_distance_matrix) #the cophenetic matrix\n",
    "    \n",
    "    cluster_merge_log = [] #the cluster merge log. Please note it logs an entry right before merging.\n",
    "    \n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return K_membership, first_distance_matrix, cophenetic_matrix, cluster_merge_log\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e15dd1a340a71bb1ac6e80fad4885450",
     "grade": true,
     "grade_id": "cell-a710ce1b995612b0",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Evaluating your hierarchical_agglomerative_clusteriong() implementation\n",
    "membership, distance_matrix, cophenetic_matrix, cluster_merge_log = \\\n",
    "        hierarchical_agglomerative_clustering(data, \n",
    "                                              K=3, \n",
    "                                              linkage_type=\"single\",\n",
    "                                              distance_metric=\"Euclidean\",\n",
    "                                              verbose=False\n",
    "                                             )\n",
    "assert (membership[0],membership[150],membership[-1])==(1,2,3)\n",
    "assert np.abs(np.sqrt(np.sum(distance_matrix**2))-4415.120866975218)<1e-4\n",
    "assert np.abs(np.sqrt(np.sum(cophenetic_matrix**2))-971.1593612790847)<1e-4\n",
    "assert len(cluster_merge_log)==311\n",
    "assert np.abs(cluster_merge_log[0][0]-0.07071067811865325)<1e-4\n",
    "assert np.abs(cluster_merge_log[-1][0]-3.8209946349085593)<1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16e020b6820b48d4af88019d5582ea66",
     "grade": false,
     "grade_id": "cell-6cacb3d7f3c58330",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task O\n",
    "* Complete the following `CCC()` function that computes the cophenetic correlation coefficient given the computed distance matrix and cophenetic matrix returned from the `hierarchical_agglomerative_clustering()` function call.\n",
    "    - please watch carefully the last part of the lecture video for the definition and examples on how to calculate the cophenetic correlation coefficient.\n",
    "* Details can be found on Slide # 72+ of lecture [Lecture-PDF](https://drive.google.com/file/d/1Tfl4tgX72a-Oy1GN_3SoV9vYgT9MnaWr/view?usp=sharing), [Lecture-Video](https://www.youtube.com/embed/mrCnL9jnsOc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "905861c84a388df4a32dea7fc6c31e47",
     "grade": false,
     "grade_id": "cell-011b54d2df8382cf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def CCC(cophenetic_matrix,distance_matrix):\n",
    "    \"\"\"\n",
    "    Compute cophenetic correlation coefficient from the given cophentic and distance matrices.\n",
    "    :param coephenetic_matrix: cophenetic matrix of data points based on hierarchical agglomerative clustering.\n",
    "    :param distance_matrix:  distance matrix of the data points.\n",
    "    :return ccc_val: the cophenetic correlation coefficient value based on its definition.\n",
    "    \n",
    "    \"\"\"\n",
    "    ccc_val = 0\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return ccc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba45d463100408f1abd8593a69447266",
     "grade": true,
     "grade_id": "cell-0bb776b775921489",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#evaluating your CCC implementation. Please note there might be hidden tests\n",
    "test_data = np.array([[1,1],[1.5,1.5],[5,5],[3,4],[4,4],[3,3.5]])\n",
    "m, d, c, l = hierarchical_agglomerative_clustering(test_data, 2,\"single\",\"Euclidean\")\n",
    "assert np.abs(CCC(c,d)-0.86399159)<1e-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c03d60ac7bf5369047a508026ffadf39",
     "grade": false,
     "grade_id": "cell-74361eee80c9cb97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task P\n",
    "* Implement the task_P() function to do the following:\n",
    "    1. perform hierarchical agglomerative clustering on the given dataset with single linkage strategy and Euclidean distance as the distance metric, and finally cut your computed dendrogram to have 3 clusters (i.e., K=3).\n",
    "    2. Draw the scatterplot of the datapoints using your computed membership. Run `ScatterPlot()` to draw the result of clustering you got, with title `Hierarchical[single,Euclidean] with k=3, SSE=x, RI=y` and replace `x, y` with the SSE and RI value of the clustering upto 2 digits after decimal point.\n",
    "* A sample \"expected\" output is shown below. Please don't copy the image below. LOL\n",
    "\n",
    "![task-p-single-euclid-k=3](figs/hierarchical_single_euclid_k_3.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad014da48210cdb985cce6c3f679f61a",
     "grade": false,
     "grade_id": "cell-3b6a79c229177789",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def task_P(data):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d28a8214dcd20f203fe0e67a0f284e4",
     "grade": true,
     "grade_id": "cell-dc9d643efedd477d",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Now, call task_P with the given data\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e8ae409e2c3c48b0e14d18a9f9670e29",
     "grade": false,
     "grade_id": "cell-b5145ecea348983c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task Q\n",
    "* Implement the task_Q() function to do the following:\n",
    "    1. perform hierarchical agglomerative clustering on the given dataset with average linkage strategy and Minkowski_3 distance as the distance metric, and finally cut your computed dendrogram to have 3 clusters (i.e., K=3).\n",
    "    2. Draw the scatterplot of the datapoints using your computed membership. Run `ScatterPlot()` to draw the result of clustering you got, with title `Hierarchical[average,Minkowski_3] with k=3, SSE=x, RI=y` and replace `x, y` with the SSE and RI value of the clustering upto 2 digits after decimal point.\n",
    "* A sample \"expected\" output is shown below. Please don't copy the image below. LOL\n",
    "\n",
    "![task-p-single-euclid-k=3](figs/hierarchical_avg_minkowski_3_k_3.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c931040028e4b22ff96d79c7ba09d4f1",
     "grade": false,
     "grade_id": "cell-2a12aa6c973093f4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def task_Q(data):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89be0383199fd05e14b464dc2e0f71ec",
     "grade": true,
     "grade_id": "cell-1b3bed0cd8612f07",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Now call task_Q\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "797dd5ca8c777fc7bfcecf7386291ab1",
     "grade": false,
     "grade_id": "cell-8a6e0988bf426689",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task R\n",
    "* Write down your answer in the following cell this question:\n",
    "\n",
    "Question: Which of the two clustering algorithm (k-means and hierarchical) was trained faster? Please explain your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e060d8db89b6bb91ebb1ac6f73f6a85",
     "grade": true,
     "grade_id": "cell-e150cf7e01c459c9",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "question_R = \"Which of the two clustering algorithm (k-means and hierarchical) was trained faster? Please Explain your answer.\"\n",
    "answer_R = \"\"\n",
    "\n",
    "#Please assign a proper answer to variable `answer_R`\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "68788bfffcc06e584dc1ba2505125e06",
     "grade": false,
     "grade_id": "cell-630219f95a18152f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task S\n",
    "* Write down your answer in the following cell this question:\n",
    "\n",
    "Question: Which of the two clustering algorithm (k-means and hierarchical) was performed best in clustering the data points? Please explain your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "544aabd5515e0b5eaa20e096bee0a124",
     "grade": true,
     "grade_id": "cell-5d7bf56ca2d6a7f2",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "question_S = \"Which of the two clustering algorithm (k-means and hierarchical) was performed best in clustering the data points? Please Explain your answer.\"\n",
    "answer_S = \"\"\n",
    "\n",
    "#Please assign a proper answer to variable `answer_S`\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
